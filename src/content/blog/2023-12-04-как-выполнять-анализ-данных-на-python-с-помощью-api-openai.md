---
title: Как выполнять анализ данных на Python с помощью API OpenAI
meta_title: Как выполнять анализ данных на Python с помощью API OpenAI - Фул Фронт Дев
date: 2023-12-04T13:58:39.931Z
image: >-
  ../../assets/images/kak-v-polniat-analyz-dann-kh-na-python-s-pomoschiu-api-openai-Dec-04-2023.avif
categories:
  - Как закодить
author: Igor Gorlov
tags:
  - Python
  - OpenAI
draft: false
type: blog
slug: kak-v-polniat-analyz-dann-kh-na-python-s-pomoschiu-api-openai
description: >-
  **В этом уроке вы узнаете, как использовать Python и API OpenAI для добычи и
  анализа данных.** Ручной анализ наборов данных для извлечения полезных данных
  или
lastmod: 2024-03-20T21:26:44.928Z
---

**В этом уроке вы узнаете, как использовать Python и API OpenAI для добычи и анализа данных.**

Ручной анализ наборов данных для извлечения полезных данных или даже использование простых программ для этого часто может быть сложным и отнимать много времени. К счастью, с помощью OpenAI API и Python можно систематически анализировать ваши наборы данных на предмет интересной информации, не перегружая код и не теряя времени. Это может использоваться как универсальное решение для анализа данных, избавляющее от необходимости использовать различные методы, библиотеки и API для анализа разных типов данных и точек данных внутри набора данных.

Давайте пройдемся по шагам использования OpenAI API и Python для анализа данных, начиная с того, как все настроить.

## Setup

Чтобы добывать и анализировать данные через Python с помощью OpenAI API, установите библиотеки `openai` и `pandas`:

```bash
pip3 install openai pandas

```

После этого создайте новую папку и создайте пустой файл Python в новой папке.

## Анализ текстовых файлов

В этом руководстве я подумал, что будет интересно заставить Python проанализировать последнее сообщение о доходах Nvidia.

Скачайте [стенограмму последнего отчета о прибылях Nvidia](https://github.com/MattNikonorov/Python_data_analysis_openai/blob/main/transcript.txt), которую я взял с сайта [The Motley Fool](https://www.fool.com/earnings/call-transcripts/2023/08/23/nvidia-nvda-q2-2024-earnings-call-transcript/), и переместите ее в папку проекта.

Затем откройте свой пустой файл Python и добавьте [этот код](https://github.com/MattNikonorov/Python_data_analysis_openai/blob/main/text_analysis.py).

Код считывает транскрипт заработка Nvidia, который вы скачали, и передает его в функцию `extract_info` в качестве переменной `transcript`.

Функция `extract_info` передает в качестве пользовательского ввода подсказку и транскрипт, а также `temperature=0.3` и `model="gpt-3.5-turbo-16k"`. Модель “gpt-3.5-turbo-16k” используется потому, что она может обрабатывать большие тексты, такие как эта расшифровка. Код получает ответ с помощью конечной точки `openai.ChatCompletion.create` и передает переменные prompt и transcript в качестве пользовательского ввода:

```python
completions = openai.ChatCompletion.create(
    model="gpt-3.5-turbo-16k",
    messages=[
        {"role": "user", "content": prompt+"\n\n "+text}
    ],
    температура=0.3,
)
```

Полный исходный текст будет выглядеть следующим образом:

```text
Извлеките из текста следующую информацию:
Доход Nvidia
Что Nvidia сделала в этом квартале
Замечания по поводу искусственного интеллекта

Стенограмма отчета о прибылях Nvidia находится здесь

```

Теперь, если мы передадим входные данные в конечную точку `openai.ChatCompletion.create`, полный вывод будет выглядеть следующим образом:

```javascript
{
  "choices": [
    {
      "finish_reason": "остановка",
      "index": 0,
      "message": {
        "content": "Фактический ответ",
        "role": "помощник"
      }
    }
  ],
  "created": 1693336390,
  "id": "request-id",
  "model": "gpt-3.5-turbo-16k-0613",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 579,
    "prompt_tokens": 3615,
    "total_tokens": 4194
  }
}
```

Как видите, он возвращает текстовый ответ, а также данные об использовании токенов в запросе, что может быть полезно, если вы отслеживаете свои расходы и оптимизируете затраты. Но поскольку нас интересует только текст ответа, мы получим его, указав путь к ответу `completions.choices[0].message.content`.

Если вы запустите свой код, вы должны получить результат, аналогичный приведенному ниже:

> Из этого текста мы можем извлечь следующую информацию:
>
> 1. Выручка Nvidia: Во втором квартале 2024 финансового года Nvidia сообщила о рекордной выручке за второй квартал в размере 13,51 миллиарда, что на 88 % больше по сравнению с предыдущим кварталом и на 101 % больше в годовом исчислении.
> 2. Что сделала Nvidia в этом квартале: Nvidia продемонстрировала исключительный рост в различных областях. Рекордный доход был получен в сегменте центров обработки данных, который вырос на 141 % по сравнению с предыдущим кварталом и на 171 % в годовом исчислении. Также был отмечен рост в игровом сегменте, где выручка увеличилась на 11 % последовательно и на 22 % в годовом исчислении. Кроме того, в сегменте профессиональной визуализации рост выручки составил 28 %. Компания также объявила о партнерстве и сотрудничестве с такими компаниями, как Snowflake, ServiceNow, Accenture, Hugging Face, VMware и SoftBank.
>    Nvidia отметила высокий спрос на свои платформы искусственного интеллекта и решения для ускоренных вычислений. Они упомянули о внедрении своих систем HGX крупными поставщиками облачных услуг и потребительскими интернет-компаниями. Они также рассказали о применении генеративного ИИ в различных отраслях, таких как маркетинг, медиа и развлечения. Nvidia подчеркнула потенциал генеративного ИИ для создания новых рыночных возможностей и повышения производительности в различных отраслях.

Как видите, код извлекает информацию, указанную в запросе (доход Nvidia, то, что Nvidia сделала в этом квартале, и замечания по поводу ИИ), и выводит ее на печать.

## Анализ CSV-файлов

Анализировать стенограммы звонков о доходах и текстовые файлы - это здорово, но для систематического анализа больших объемов данных вам понадобится работа с CSV-файлами.

В качестве рабочего примера скачайте [this Medium articles CSV dataset](https://github.com/MattNikonorov/Python_data_analysis_openai/blob/main/articles.csv) и вставьте его в свой файл проекта.

Если вы посмотрите на CSV-файл, то увидите, что в нем есть колонки ”автор", "хлопки", "чтение_время", "ссылка", "заголовок" и "текст". Для анализа средних статей с помощью OpenAI вам понадобятся только столбцы "заголовок" и "текст".

Создайте новый файл Python в папке проекта и вставьте [этот код](https://github.com/MattNikonorov/Python_data_analysis_openai/blob/main/csv_analysis.py).

Этот код немного отличается от кода, который мы использовали для анализа текстового файла. Он читает строки CSV одну за другой, извлекает указанные фрагменты информации и добавляет их в новые столбцы.

Для этого урока я выбрал CSV-данные статей Medium, которые я получил от [HSANKESARA](https://www.kaggle.com/datasets/hsankesara/medium-articles) на Kaggle. Этот код анализа CSV найдет общий тон и основной урок/тезис каждой статьи, используя столбцы ”заголовок" и "статья" CSV-файла. Поскольку на Medium я постоянно натыкаюсь на статьи с "кликбейтом", я подумал, что было бы интересно попросить его определить, насколько "кликбейтной" является каждая статья, присвоив каждой из них "оценку кликбейта" от 0 до 3, где 0 - это отсутствие кликбейта, а 3 - экстремальный кликбейт.

Прежде чем я объясню код, анализ всего CSV-файла занял бы слишком много времени и стоил бы слишком много кредитов API, поэтому для этого руководства я заставил код проанализировать только первые пять статей, используя `df = df[:5]`.

Вас может смутить следующая часть кода, поэтому позвольте мне объяснить:

```python
for di in range(len(df)):
title = titles[di]
abstract = articles[di]
additional_params = extract_info('Title: '+str(title) + '\n\n' + 'Text: ' + str(abstract))
try:
result = additional_params.split("\n\n")
except:
result = {}

```

Этот код перебирает все статьи (строки) в CSV-файле и при каждой итерации получает заголовок и тело каждой статьи и передает их в функцию `extract_info`, которую мы видели ранее. Затем он превращает ответ функции `extract_info` в список, чтобы разделить различные части информации с помощью этого кода:

```python
try:
    result = additional_params.split("\n\n")
except:
    result = {}
```

Далее он добавляет каждую часть информации в список, а в случае ошибки (если нет значения) добавляет в список “No result”:

```python
try:
apa1.append(result[0])
except Exception as e:
apa1.append('No result')
try:
apa2.append(result[1])
except Exception as e:
apa2.append('No result')
try:
apa3.append(result[2])
except Exception as e:
apa3.append('No result')

```

Наконец, после завершения цикла `for` списки, содержащие извлеченную информацию, вставляются в новые колонки CSV-файла:

```python
df = df.assign(Tone=apa1)
df = df.assign(Основной_урок_или_пункт=apa2)
df = df.assign(Clickbait_score=apa3)
```

Как вы можете видеть, он добавляет списки в новые столбцы CSV с именами ”Тон", "Основной*беседа*ор_пункт” и “Clickbait_score”.

Затем он добавляет их в CSV-файл с `index=False`:

```python
df.to_csv("data.csv", index=False)

```

Причина, по которой необходимо указать `index=False`, заключается в том, чтобы избежать создания новых индексных столбцов каждый раз, когда вы добавляете новые столбцы в CSV-файл.

Теперь, если вы запустите свой Python-файл, дождетесь его завершения и просмотрите наш CSV-файл в программе просмотра CSV-файлов, вы увидите новые столбцы, как показано на рисунке ниже.

![Демонстрация столбцов](https://uploads.sitepoint.com/wp-content/uploads/2023/08/1693540464columns.jpg)

Если вы запустите код несколько раз, то заметите, что сгенерированные ответы немного отличаются. Это потому, что код использует `temperature=0.3`, чтобы добавить немного креатива в свои ответы, что полезно для субъективных тем, таких как кликбейт.

## Работа с несколькими файлами

Если вы хотите автоматически проанализировать несколько файлов, вам нужно сначала поместить их в папку и убедиться, что папка содержит только те файлы, которые вас интересуют, чтобы ваш код Python не читал нерелевантные файлы. Затем установите библиотеку `glob` с помощью `pip3 install glob` и импортируйте ее в ваш Python-файл с помощью `import glob`.

В вашем Python-файле используйте этот код, чтобы получить список всех файлов в папке data:

```python
data_files = glob.glob("data_folder/*")
```

Затем поместите код, выполняющий анализ, в цикл `for`:

```python
for i in range(len(data_files)):

```

Внутри цикла `for` прочитайте содержимое каждого файла следующим образом для текстовых файлов:

```python
f = open(f "data_folder/{data_files[i]}", "r")
txt_data = f.read()
```

Также это можно сделать для файлов CSV:

```python
df = pd.read_csv(f "data_folder/{data_files[i]}")

```

Кроме того, не забудьте сохранить результаты анализа каждого файла в отдельный файл, используя что-то вроде этого:

```python
df.to_csv(f "output_folder/data{i}.csv", index=False)
```

## Заключение

Не забывайте экспериментировать с параметром температуры и подстраивать его под свой случай использования. Если вы хотите, чтобы ИИ давал более креативные ответы, увеличьте температуру, а если хотите, чтобы он давал более фактические ответы, уменьшите ее.

Сочетание OpenAI и Python для анализа данных имеет множество применений, помимо анализа статей и стенограмм звонков о доходах. Например, анализ новостей, анализ книг, анализ отзывов покупателей и многое другое! При этом, тестируя свой Python-код на больших массивах данных, убедитесь, что тестируете его только на небольшой части полного массива данных, чтобы сэкономить кредиты API и время.
