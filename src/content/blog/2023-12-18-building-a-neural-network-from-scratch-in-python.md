---
title: Создание нейронной сети с нуля на Python
meta_title: Создание нейронной сети с нуля на Python | Игорь Горлов - Фронтeндер
description: >-
  Нейронные сети  это мощные модели машинного обучения, созданные на основе
  структуры и работы человеческого мозга. В этом уроке мы рассмотрим процесс
  создания
date: 2023-12-18T00:00:00.000Z
categories:
  - Учебник
author: Игорь Горлов
type: blog
draft: false
slug: sozdanye-neironnoi-sety-s-nulia-na-python
tags:
  - Python
  - Ai
image: ../../assets/images/sozdanye-neironnoi-sety-s-nulia-na-python-Dec-18-2023.avif
lastmod: 2024-03-20T21:26:44.135Z
---

Нейронные сети - это мощные модели машинного обучения, созданные на основе структуры и работы человеческого мозга. В этом уроке мы рассмотрим процесс создания базовой нейронной сети с нуля с помощью Python.  
Вычислительная модель, называемая нейронной сетью, основана на том, как работает и устроен человеческий мозг. Это эффективная техника, используемая в искусственном интеллекте и машинном обучении для решения таких задач, как классификация, регрессия, распознавание образов и многое другое.

Основными элементами нейронной сети являются взаимосвязанные узлы, или ”нейроны", расположенные слоями. Передача и обработка информации осуществляются этими нейронами. Вот краткое объяснение того, из чего состоит нейронная сеть:

Входной слой: Этот слой принимает вводную информацию или характеристики и передает их на следующий слой. Аспект входных данных представлен каждым нейроном в этом слое.

Скрытые слои: Между входным и выходным слоями может быть один или несколько слоев, известных как скрытые слои. Эти слои обрабатывают данные, выполняя вычисления. Каждый нейрон в скрытом слое связан с каждым другим нейроном в слое выше и ниже его.

Веса: Каждое соединение нейронов имеет соответствующий вес, который отражает силу связи. Эти веса изменяются в процессе обучения, чтобы уменьшить ошибку предсказания.

Функция активации: Каждый нейрон применяет функцию активации к взвешенной сумме своих входов. Эта функция вносит нелинейность в модель, позволяя нейронной сети изучать сложные взаимосвязи.

Выходной слой: Последний слой производит выходной сигнал сети. Количество нейронов в этом слое зависит от типа задачи, которую призвана решить сеть. Например, при бинарной классификации может быть один нейрон, выдающий на выходе значения от 0 до 1.

Смещение: каждый нейрон также имеет член смещения, который позволяет ему иметь определенную гибкость в активации. Это важно для обучения различным шаблонам.

## Пререквизиты

Прежде чем мы начнем, убедитесь, что в вашей системе установлена последняя версия Python. Мы будем использовать библиотеку NumPy для численных вычислений. Если вы еще не установили NumPy, выполните команду:

`pip install numpy`.

## Шаг 1: Инициализация весов и погрешностей

Первым шагом в построении нейронной сети является инициализация весов и смещений. Мы создадим простую нейронную сеть с одним входным слоем, одним скрытым слоем и одним выходным слоем.

`import numpy as np # Определяем архитектуру нейронной сети input_size = 2 hidden_size = 3 output_size = 1 # Инициализируем веса и смещения weights_input_hidden = np.random.randn(input_size, hidden_size) bias_hidden = np.zeros((1, hidden_size)) weights_hidden_output = np.random.randn(hidden_size, output_size) bias_output = np.zeros((1, output_size)) `

## Шаг 2: Определите функции активации

Функции активации вносят нелинейность в нейронную сеть, позволяя ей обучаться сложным паттернам.

`def sigmoid(x): return 1 / (1 + np.exp(-x)) def sigmoid_derivative(x): return x * (1 - x)`

## Что такое сигмоидальная функция?

Сигмоидальная функция - это математическая функция, которая отображает любое вещественное число на значение между 0 и 1. Наиболее часто используемая сигмоидальная функция - это логистическая функция, также известная как стандартная логистическая функция. Сигмоидальная функция имеет тенденцию сжимать очень большие положительные или отрицательные входы до очень близких к 0 или 1, соответственно. Это может привести к проблеме исчезающего градиента в глубоком обучении, что может сделать обучение более медленным и менее стабильным. По этой причине другие функции активации, такие как ReLu (Rectified Linear Unit), стали более популярными во многих архитектурах нейронных сетей. Но в этом уроке мы будем использовать только сигмоидальную функцию.

`def sigmoid(x): return 1 / (1 + np.exp(-x)) def sigmoid_derivative(x): return x * (1 - x)`

## Шаг 3: Определение прямого прохода

Прямой проход включает в себя вычисление выхода нейронной сети с учетом входных данных.

`def forward(x): hidden_input = np.dot(x, weights_input_hidden) + bias_hidden hidden_output = sigmoid(hidden_input) final_input = np.dot(hidden_output, weights_hidden_output) + bias_output final_output = sigmoid(final_input) return final_output `

## Шаг 4: Определите алгоритм обратного распространения

Обратное распространение используется для обновления весов и смещений на основе ошибки в предсказаниях.

`def backward(x, y, output): error = y - output d_output = error * sigmoid_derivative(output) error_hidden = d_output.dot(weights_hidden_output.T) d_hidden = error_hidden * sigmoid_derivative(hidden_output) weights_hidden_output += hidden_output.T.dot(d_output) * скорость обучения weights_input_hidden += x.T.dot(d_hidden) * скорость обучения bias_output += np.sum(d_output, axis=0, keepdims=True) * скорость обучения bias_hidden += np.sum(d_hidden, axis=0, keepdims=True) * скорость обучения `

## Шаг 5: Обучение нейронной сети

Теперь давайте обучим нейронную сеть, передав ей простой набор данных.

`# Определим набор данных X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])y = np.array([[0], [1], [1], [0]]) # Задаем гиперпараметры learning_rate = 0.1 epochs = 10000 # Обучаем нейронную сеть for epoch in range(epochs): output = forward(X) backward(X, y, output) # Тестируем обученную сеть output = forward(X) print("Итоговый результат после обучения:") print(output) `

## Последние мысли

В этой статье мы показали, как создать фундаментальную нейронную сеть на Python с нуля. Инициализация весов, создание функций активации, применение прямого прохода на практике и обратное распространение для обучения - все эти темы мы рассмотрели. Это дает фундаментальный обзор нейронных сетей и может послужить трамплином для более глубоких исследований в области глубокого обучения.

Вот статья, в которой мы подробно рассказываем о том, как работает нейронная сеть.
